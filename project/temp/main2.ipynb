{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alito\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import definitions as df\n",
    "import data_manipulation as dm\n",
    "import sql_def as sql\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plots\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import math\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grabing the data from SQL dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_database = r\"./data\"\n",
    "path_to_code = r\"./\"\n",
    "os.chdir(path_to_database)\n",
    "track_from_sql =  sql.data_from_sql(\"database.db\", \"SELECT * FROM TRACKMATEDATA\")\n",
    "os.chdir(path_to_code)\n",
    "track_with_frame = df.separate_trajectories(track_from_sql)\n",
    "trajectories1 = df.separate_data(track_with_frame, False)\n",
    "trajectories = []\n",
    "for temp in trajectories1:\n",
    "    f2 = []\n",
    "    c = 1\n",
    "    for t1 in temp:\n",
    "        f2.append(t1)\n",
    "        c += 1\n",
    "        if c == 10:\n",
    "            break\n",
    "    trajectories.append(f2)\n",
    "trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Fake data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = 12000\n",
    "max_x = 1000\n",
    "max_y = 1000\n",
    "min_x = 0\n",
    "min_y = 0\n",
    "track_len = 20\n",
    "\n",
    "trajectories = dm.create_synthetic(total_size, max_x, max_y, min_x, min_y, track_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10800\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "train_norm, test_norm = df.split_test_train(trajectories)\n",
    "train, min_x, min_y, range_x, range_y = df.normalize_data(train_norm)\n",
    "test, min_x, min_y, range_x, range_y = df.normalize_data(test_norm, min_x, min_y, range_x, range_y)\n",
    "train_data, train_masked_point = df.mask_point_at_index(train, 6)\n",
    "test_data, test_masked_point = df.mask_point_at_index(test, 6)\n",
    "\n",
    "print(len(train_data))\n",
    "print(len(test_masked_point))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "tensor([[[0.3367, 0.5637],\n",
      "         [0.3382, 0.5637],\n",
      "         [0.3396, 0.5637],\n",
      "         ...,\n",
      "         [0.3617, 0.5637],\n",
      "         [0.3632, 0.5637],\n",
      "         [0.3647, 0.5637]],\n",
      "\n",
      "        [[0.8358, 0.1929],\n",
      "         [0.8333, 0.1875],\n",
      "         [0.8309, 0.1822],\n",
      "         ...,\n",
      "         [0.7935, 0.1015],\n",
      "         [0.7910, 0.0961],\n",
      "         [0.7885, 0.0908]],\n",
      "\n",
      "        [[0.2601, 0.4213],\n",
      "         [0.2653, 0.4217],\n",
      "         [0.2704, 0.4221],\n",
      "         ...,\n",
      "         [0.3475, 0.4275],\n",
      "         [0.3527, 0.4279],\n",
      "         [0.3578, 0.4282]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.7968, 0.5370],\n",
      "         [0.7971, 0.5385],\n",
      "         [0.7973, 0.5400],\n",
      "         ...,\n",
      "         [0.8012, 0.5619],\n",
      "         [0.8014, 0.5633],\n",
      "         [0.8017, 0.5648]],\n",
      "\n",
      "        [[0.6783, 0.6609],\n",
      "         [0.6823, 0.6628],\n",
      "         [0.6863, 0.6646],\n",
      "         ...,\n",
      "         [0.7463, 0.6929],\n",
      "         [0.7503, 0.6947],\n",
      "         [0.7543, 0.6966]],\n",
      "\n",
      "        [[0.5914, 0.4391],\n",
      "         [0.5972, 0.4405],\n",
      "         [0.6029, 0.4418],\n",
      "         ...,\n",
      "         [0.6890, 0.4618],\n",
      "         [0.6947, 0.4632],\n",
      "         [0.7004, 0.4645]]])\n",
      "src_data_tensor shape: torch.Size([10800, 20, 2])\n",
      "tgt_data_tensor shape: torch.Size([10800, 20, 2])\n",
      "src_masks_tensor shape: torch.Size([10800, 20, 2])\n"
     ]
    }
   ],
   "source": [
    "src_data_tensor, tgt_data_tensor, src_masks_tensor = df.prepare_data_for_transformer(train_data, train_masked_point)\n",
    "\n",
    "## DEBUG\n",
    "print(src_data_tensor)\n",
    "print(\"src_data_tensor shape:\", src_data_tensor.shape)\n",
    "print(\"tgt_data_tensor shape:\", tgt_data_tensor.shape)\n",
    "print(\"src_masks_tensor shape:\", src_masks_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alito\\Desktop\\NanceLab\\DeepLearning-Model\\diff_transformers\\project\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alito\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "import model as md\n",
    "\n",
    "input_dim = 2\n",
    "hidden_dim = 64                                                                                   \n",
    "output_dim = 2\n",
    "rate = 0.0001\n",
    "\n",
    "model = md.SelfSupervisedModel(in_channels=3, out_channels=128, input_dim=128, model_dim=256, num_heads=8, num_layers=6, output_dim=3)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=rate) ## w \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(src_data_tensor, tgt_data_tensor, src_masks_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 3 required positional arguments: 'edge_index', 'src', and 'tgt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19228\\2529017933.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mmasked_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;31m# output[:, 6, :]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmasked_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alito\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1510\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1511\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alito\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1518\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1522\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() missing 3 required positional arguments: 'edge_index', 'src', and 'tgt'"
     ]
    }
   ],
   "source": [
    "n_iters = 10\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    total_loss = 0\n",
    "    for src, tgt, mask in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src)\n",
    "        masked_output = output # output[:, 6, :]\n",
    "        loss = loss_function(masked_output, tgt)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}/{n_iters}, Loss: {total_loss / len(dataloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Src shape: torch.Size([32, 20, 2]), Tgt shape: torch.Size([32, 20, 2]), Mask shape: torch.Size([32, 20, 2])\n",
      "tensor([[[False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [ True,  True],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False]],\n",
      "\n",
      "        [[False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [ True,  True],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False]],\n",
      "\n",
      "        [[False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [ True,  True],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False],\n",
      "         [False, False]]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 32 but got size 2 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19228\\1483366439.py\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m# Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# Compute loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alito\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1510\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1511\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alito\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1518\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1522\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alito\\Desktop\\NanceLab\\DeepLearning-Model\\diff_transformers\\project\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, edge_index, src, tgt, src_mask, tgt_mask)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[0mgnn_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mtransformer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgnn_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtransformer_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alito\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1510\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1511\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alito\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1518\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1522\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alito\\Desktop\\NanceLab\\DeepLearning-Model\\diff_transformers\\project\\model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alito\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1510\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1511\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alito\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1518\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1521\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1522\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alito\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    239\u001b[0m                 \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_edge_index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m                     edge_index, edge_weight = gcn_norm(  # yapf: disable\n\u001b[0m\u001b[0;32m    242\u001b[0m                         \u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m                         self.improved, self.add_self_loops, self.flow, x.dtype)\n",
      "\u001b[1;32mc:\\Users\\alito\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py\u001b[0m in \u001b[0;36mgcn_norm\u001b[1;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0madd_self_loops\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         edge_index, edge_weight = add_remaining_self_loops(\n\u001b[0m\u001b[0;32m    100\u001b[0m             edge_index, edge_weight, fill_value, num_nodes)\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alito\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch_geometric\\utils\\loop.py\u001b[0m in \u001b[0;36madd_remaining_self_loops\u001b[1;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[0;32m    652\u001b[0m         \u001b[0medge_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_undirected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_undirected\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m     \u001b[0medge_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alito\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch_geometric\\edge_index.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m   1055\u001b[0m         \u001b[1;31m# implement specific functions for valid `EdgeIndex` routines.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mHANDLED_FUNCTIONS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1057\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mHANDLED_FUNCTIONS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1058\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[1;31m# For all other PyTorch functions, we return a vanilla PyTorch tensor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alito\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch_geometric\\edge_index.py\u001b[0m in \u001b[0;36mcat\u001b[1;34m(tensors, dim, out)\u001b[0m\n\u001b[0;32m   1202\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1204\u001b[1;33m     output = Tensor.__torch_function__(torch.cat, (Tensor, ), (tensors, dim),\n\u001b[0m\u001b[0;32m   1205\u001b[0m                                        dict(out=out))\n\u001b[0;32m   1206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\alito\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36m__torch_function__\u001b[1;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[0;32m   1416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDisableTorchFunctionSubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1419\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfunc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mget_default_nowrap_functions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 32 but got size 2 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "## TEMP\n",
    "n_iters = 40\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "threshold = 0.01\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Example DataLoader setup\n",
    "\n",
    "# Lists to store loss and accuracy values for each epoch\n",
    "loss_values = []\n",
    "accuracy_values = []\n",
    "\n",
    "def compute_accuracy(predictions, targets, threshold=0.01):\n",
    "    distances = torch.sqrt(torch.sum((predictions - targets) ** 2, dim=1))\n",
    "    accurate_predictions = distances < threshold\n",
    "    accuracy = torch.mean(accurate_predictions.float()) * 100\n",
    "    return accuracy.item()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_iters):\n",
    "    total_loss = 0\n",
    "    model.train()  # Set the model to training mode\n",
    "    for src, tgt, mask in dataloader:\n",
    "        print(f'Src shape: {src.shape}, Tgt shape: {tgt.shape}, Mask shape: {mask.shape}')\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(src, mask, src, tgt)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(output, tgt)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    loss_values.append(avg_loss)\n",
    "    print(f'Epoch {epoch+1}/{n_iters}, Loss: {avg_loss}')\n",
    "\n",
    "    # Evaluation phase\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        t_src_data_tensor, t_tgt_data_tensor, t_src_masks_tensor = df.prepare_data_for_transformer(test_data, test_masked_point)\n",
    "        \n",
    "        predictions = model(t_src_data_tensor, t_src_masks_tensor, t_src_data_tensor, t_tgt_data_tensor)\n",
    "        \n",
    "        accuracy = compute_accuracy(predictions, t_tgt_data_tensor, threshold=threshold)\n",
    "        accuracy_values.append(accuracy)\n",
    "        print(f'Accuracy after Epoch {epoch+1}/{n_iters}: {accuracy:.2f}%')\n",
    "\n",
    "# Plotting loss and accuracy\n",
    "epochs = range(1, n_iters + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, loss_values, 'b', label='Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, accuracy_values, 'g', label='Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "t_src_data_tensor, t_tgt_data_tensor, t_src_masks_tensor = df.prepare_data_for_transformer(test_data, test_masked_point)\n",
    "X_test = t_src_data_tensor[3]\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test)\n",
    "    print(X_test)\n",
    "    print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_src_data_tensor[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions, targets, threshold=0.000001):\n",
    "    distances = torch.sqrt(torch.sum((predictions - targets) ** 2, dim=1))\n",
    "    accurate_predictions = distances < threshold\n",
    "    accuracy = torch.mean(accurate_predictions.float()) * 100\n",
    "    return accuracy.item()\n",
    "predictions = model(t_src_data_tensor)\n",
    "acc = compute_accuracy(predictions, t_tgt_data_tensor, 0.05)\n",
    "print('accuracy of model to predict a point: {:.2f} %'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEMP\n",
    "\n",
    "loss_values = []\n",
    "accuracy_values = []\n",
    "\n",
    "for epoch in range(40):\n",
    "    total_loss = 0\n",
    "    model.train()  # Set the model to training mode\n",
    "    for src, tgt, mask in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src)\n",
    "        masked_output = output  # output[:, 6, :]\n",
    "        loss = loss_function(masked_output, tgt)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    loss_values.append(avg_loss)\n",
    "    print(f'Epoch {epoch+1}/{n_iters}, Loss: {avg_loss}')\n",
    "\n",
    "    # Evaluation phase\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        t_src_data_tensor, t_tgt_data_tensor, t_src_masks_tensor = df.prepare_data_for_transformer(test_data, test_masked_point)\n",
    "        print(t_tgt_data_tensor[2])\n",
    "        predictions = model(t_src_data_tensor)\n",
    "        print(predictions[2])\n",
    "        accuracy = compute_accuracy(predictions, t_tgt_data_tensor, threshold=0.01)\n",
    "        print(accuracy)\n",
    "        accuracy_values.append(accuracy)\n",
    "        print(f'Accuracy after Epoch {epoch+1}/{n_iters}: {accuracy:.2f}%')\n",
    "\n",
    "# Plotting loss and accuracy\n",
    "epochs = range(1, 40 + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, loss_values, 'b', label='Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, accuracy_values, 'r', label='Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Model Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(t_src_data_tensor)\n",
    "print(t_src_data_tensor)\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unnormalize_data(normalized_data, min_x, min_y, range_x, range_y):\n",
    "    unnormalized_data = [[(float(point[0] * range_x + min_x), float(point[1] * range_y + min_y)) if point is not None else None for point in seq] for seq in normalized_data]\n",
    "    return unnormalized_data\n",
    "\n",
    "def unnormalize_data_pred(normalized_data, min_x, min_y, range_x, range_y):\n",
    "    unnormalized_data = [(float(seq[0] * range_x + min_x), float(seq[1] * range_y + min_y)) for seq in normalized_data]\n",
    "    return unnormalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = unnormalize_data(t_src_data_tensor, min_x, min_y, range_x, range_y)\n",
    "pred = unnormalize_data_pred(predictions, min_x, min_y, range_x, range_y)\n",
    "data = torch.FloatTensor(data)\n",
    "pred = torch.FloatTensor(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_src_data_tensor = torch.tensor(t_src_data_tensor)\n",
    "predictions = torch.tensor(predictions)\n",
    "\n",
    "# Create a plot for tensors\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(data[:, 0], data[:, 1], color='blue', label='Tensor Data Points')\n",
    "plt.scatter(pred[0], pred[1], color='red', label='Prediction')\n",
    "plt.title('Tensor Data and Prediction')\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.xlim(0, 2000)\n",
    "plt.ylim(0, 2000)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"straightLine.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_data_tensor[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_src_data_tensor = torch.tensor(t_src_data_tensor)\n",
    "predictions = torch.tensor(predictions)\n",
    "\n",
    "# Create a plot for tensors\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(data[:, 0], data[:, 1], color='blue', label='Tensor Data Points')\n",
    "plt.scatter(pred[0], pred[1], color='red', label='Prediction')\n",
    "plt.title('Tensor Data and Prediction')\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.xlim(0, 2000)\n",
    "plt.ylim(0, 2000)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"straightLine.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_syn(random_trajectories=[], pred=[]):\n",
    "    if(len(random_trajectories) == 0):\n",
    "        random_trajectories = dm.create_synthetic(3)\n",
    "    for trajectory in random_trajectories:\n",
    "        print(trajectory)\n",
    "        x_values = [point[0] for point in trajectory]\n",
    "        y_values = [point[1] for point in trajectory] \n",
    "        plt.plot(x_values, y_values)\n",
    "        print(\"hi\")\n",
    "    plt.scatter(pred[0], pred[1], color='red', label='Prediction')\n",
    "\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.xlim(0, 2000)\n",
    "    plt.ylim(0, 2000)\n",
    "    plt.title('Trajectories')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_ten_arrays = data[3:4]\n",
    "\n",
    "# Now exclude the element at index 6 from each of these sub-arrays\n",
    "result_tensor = torch.cat((first_ten_arrays[:, :6], first_ten_arrays[:, 7:]), dim=1)\n",
    "\n",
    "plot_syn(result_tensor, pred[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[3:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_data_tensor[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions, targets, threshold=0.1):\n",
    "    distances = torch.sqrt(torch.sum((predictions - targets) ** 2, dim=1))\n",
    "    accurate_predictions = distances < threshold\n",
    "    accuracy = torch.mean(accurate_predictions.float()) * 100\n",
    "    return accuracy.item()\n",
    "predictions = model(t_src_data_tensor)\n",
    "acc = compute_accuracy(predictions, t_tgt_data_tensor, 0.05)\n",
    "print('accuracy of model to predict a point: {:.2f} %'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_tgt_data_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = unnormalize_data_pred(t_tgt_data_tensor, min_x, min_y, range_x, range_y)\n",
    "torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = unnormalize_data_pred(t_tgt_data_tensor, min_x, min_y, range_x, range_y)\n",
    "pred = unnormalize_data_pred(predictions, min_x, min_y, range_x, range_y)\n",
    "acc = compute_accuracy(torch.tensor(pred), torch.tensor(data), 10)\n",
    "print('accuracy of model to predict a point: {:.2f} %'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(x[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_syn(random_trajectories=[], pred=[], y=[]):\n",
    "    if(len(random_trajectories) == 0):\n",
    "        random_trajectories = dm.create_synthetic(3)\n",
    "    for trajectory in random_trajectories:\n",
    "        print(trajectory)\n",
    "        x_values = [point[0] for point in trajectory]\n",
    "        y_values = [point[1] for point in trajectory] \n",
    "        plt.plot(x_values, y_values)\n",
    "        print(\"hi\")\n",
    "    plt.scatter(pred[0], pred[1], color='red', label='Prediction')\n",
    "    plt.scatter(y[0], y[1], color='blue', label='Actual') \n",
    "\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('Y')\n",
    "    plt.xlim(650, 700)\n",
    "    plt.ylim(650, 700)\n",
    "    plt.title('Trajectories')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(\"straighLine.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_point = torch.tensor(y[3]).unsqueeze(0)  # Make it (1, 2)\n",
    "# Expand this point to match the first dimension of first_ten_arrays\n",
    "expanded_point = single_point.expand(first_ten_arrays.size(0), -1, -1)  # Expand to (10, 1, 2)\n",
    "\n",
    "# Concatenate the point between the two segments\n",
    "result_tensor = torch.cat((first_ten_arrays[:, :6], expanded_point, first_ten_arrays[:, 7:]), dim=1)\n",
    "\n",
    "print(result_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "  if(np.abs(y[i][0] - y[i][1]) < 100):\n",
    "    print(i)\n",
    "    print(y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = unnormalize_data(t_src_data_tensor, min_x, min_y, range_x, range_y)\n",
    "y = unnormalize_data_pred(t_tgt_data_tensor, min_x, min_y, range_x, range_y)\n",
    "\n",
    "index = 22\n",
    "\n",
    "print(x[index])\n",
    "print(pred[index])\n",
    "print(y[index])\n",
    "first_ten_arrays = torch.tensor(x[index:index+1])\n",
    "\n",
    "# Now exclude the element at index 6 from each of these sub-arrays\n",
    "single_point = torch.tensor(y[index]).unsqueeze(0)  # Make it (1, 2)\n",
    "# Expand this point to match the first dimension of first_ten_arrays\n",
    "expanded_point = single_point.expand(first_ten_arrays.size(0), -1, -1)  # Expand to (10, 1, 2)\n",
    "\n",
    "# Concatenate the point between the two segments\n",
    "result_tensor = torch.cat((first_ten_arrays[:, :6], expanded_point, first_ten_arrays[:, 7:]), dim=1)\n",
    "              \n",
    "plot_syn(result_tensor, torch.tensor(pred[index]),  torch.tensor(y[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(x[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t_tgt_data_tensor[0])\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0 * range_x + min_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data, min_x=0, min_y=0, range_x=0, range_y=0):\n",
    "    # (x, y) -> needs to be the data, otherwise i gotta rewrite possibly\n",
    "    # can assume with none\n",
    "    all_points = [point for seq in data for point in seq if point is not None]\n",
    "    if range_x or range_y == 0 or min_x == 0 or min_y == 0:\n",
    "        all_x = [point[0] for point in all_points]\n",
    "        all_y = [point[1] for point in all_points] \n",
    "\n",
    "        min_x = min(all_x)\n",
    "        max_x = max(all_x)\n",
    "        min_y = min(all_y)\n",
    "        max_y = max(all_y)\n",
    "        range_x = max_x - min_x\n",
    "        range_y = max_y - min_y\n",
    "        print(min_x)\n",
    "\n",
    "    # Normalize data\n",
    "    normalized_data = []\n",
    "    for seq in data:\n",
    "        normalized_seq = [(float(point[0] - min_x) / range_x, float(point[1] - min_y) / range_y) if point is not None else None for point in seq]\n",
    "        normalized_data.append(normalized_seq)\n",
    "\n",
    "    return normalized_data, min_x, min_y, range_x, range_y\n",
    "\n",
    "train, min_x, min_y, range_x, range_y = normalize_data(train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_points = [point for seq in train_norm for point in seq if point is not None]\n",
    "\n",
    "all_x = [point[0] for point in all_points]\n",
    "all_y = [point[1] for point in all_points] \n",
    "\n",
    "print(min(all_x))\n",
    "m = min(all_y)\n",
    "for ele in all_points:\n",
    "  if ele[1] == m:\n",
    "    print(ele)\n",
    "# print(len(train_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Example DataLoader setup\n",
    "\n",
    "    # Lists to store loss and accuracy values for each epoch\n",
    "    # loss_values = []\n",
    "    # accuracy_values = []\n",
    "\n",
    "    # # Training loop\n",
    "    # for epoch in range(n_iters):\n",
    "    #     total_loss = 0\n",
    "    #     model.train()  # Set the model to training mode\n",
    "    #     for src, tgt, mask in dataloader:\n",
    "    #         print(f'Src shape: {src.shape}, Tgt shape: {tgt.shape}, Mask shape: {mask.shape}')\n",
    "    #         optimizer.zero_grad()\n",
    "            \n",
    "    #         # Forward pass\n",
    "    #         output = model(src, mask, src, tgt)\n",
    "            \n",
    "    #         # Compute loss\n",
    "    #         loss = criterion(output, tgt)\n",
    "    #         loss.backward()\n",
    "    #         optimizer.step()\n",
    "\n",
    "    #         total_loss += loss.item()\n",
    "    #     avg_loss = total_loss / len(dataloader)\n",
    "    #     loss_values.append(avg_loss)\n",
    "    #     print(f'Epoch {epoch+1}/{n_iters}, Loss: {avg_loss}')\n",
    "\n",
    "    #     # Evaluation phase\n",
    "    #     model.eval()  # Set the model to evaluation mode\n",
    "    #     with torch.no_grad():\n",
    "    #         t_src_data_tensor, t_tgt_data_tensor, t_src_masks_tensor = df.prepare_data_for_transformer(test_data, test_masked_point)\n",
    "            \n",
    "    #         predictions = model(t_src_data_tensor, t_src_masks_tensor, t_src_data_tensor, t_tgt_data_tensor)\n",
    "            \n",
    "    #         accuracy = compute_accuracy(predictions, t_tgt_data_tensor, threshold=threshold)\n",
    "    #         accuracy_values.append(accuracy)\n",
    "    #         print(f'Accuracy after Epoch {epoch+1}/{n_iters}: {accuracy:.2f}%')\n",
    "\n",
    "    # # Plotting loss and accuracy\n",
    "    # epochs = range(1, n_iters + 1)\n",
    "\n",
    "    # plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # # Plot loss\n",
    "    # plt.subplot(1, 2, 1)\n",
    "    # plt.plot(epochs, loss_values, 'b', label='Loss')\n",
    "    # plt.xlabel('Epochs')\n",
    "    # plt.ylabel('Loss')\n",
    "    # plt.title('Training Loss')\n",
    "    # plt.legend()\n",
    "\n",
    "    # # Plot accuracy\n",
    "    # plt.subplot(1, 2, 2)\n",
    "    # plt.plot(epochs, accuracy_values, 'g', label='Accuracy')\n",
    "    # plt.xlabel('Epochs')\n",
    "    # plt.ylabel('Accuracy (%)')\n",
    "    # plt.title('Model Accuracy')\n",
    "    # plt.legend()\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
