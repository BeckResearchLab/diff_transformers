{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import definitions as df\n",
    "import data_manipulation as dm\n",
    "import norm_def as nd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import model as md\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import sql_def as sql\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_database = r\"./data\"\n",
    "# path_to_code = r\"./\"\n",
    "# os.chdir(path_to_database)\n",
    "# track_from_sql =  sql.data_from_sql(\"database.db\", \"SELECT * FROM TRACKMATEDATA\")\n",
    "# os.chdir(path_to_code)\n",
    "# track_with_frame = df.separate_trajectories(track_from_sql)\n",
    "# trajectories1 = df.separate_data(track_with_frame, False)\n",
    "# trajectories = []\n",
    "# for temp in trajectories1:\n",
    "#     f2 = []\n",
    "#     c = 1\n",
    "#     for t1 in temp:\n",
    "#         f2.append(t1)\n",
    "#         c += 1\n",
    "#         if c == 10:\n",
    "#             break\n",
    "#     trajectories.append(f2)\n",
    "# trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "hello\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "total_size = 120000\n",
    "max_x = 1000\n",
    "max_y = 1000\n",
    "min_x = 0\n",
    "min_y = 0\n",
    "track_len = 20\n",
    "\n",
    "trajectories = dm.create_synthetic(total_size, max_x, max_y, min_x, min_y, track_len)\n",
    "\n",
    "train_norm, val_norm, test_norm = df.split_data(trajectories, train_percent=70, val_percent=20)\n",
    "train, min_x, min_y, range_x, range_y = nd.normalize_data(train_norm)\n",
    "val, _, _, _, _ = nd.normalize_data(val_norm, min_x, min_y, range_x, range_y)\n",
    "test, _, _, _, _ = nd.normalize_data(test_norm, min_x, min_y, range_x, range_y)\n",
    "\n",
    "# Mask the point at index 6\n",
    "train_data, train_masked_point = df.mask_point_at_index(train, 6)\n",
    "val_data, val_masked_point = df.mask_point_at_index(val, 6)\n",
    "test_data, test_masked_point = df.mask_point_at_index(test, 6)\n",
    "\n",
    "# Prepare the data tensors\n",
    "src_data_tensor, tgt_data_tensor, src_masks_tensor = df.prepare_data_for_transformer(train_data, train_masked_point)\n",
    "val_src_data_tensor, val_tgt_data_tensor, val_src_masks_tensor = df.prepare_data_for_transformer(val_data, val_masked_point)\n",
    "test_src_data_tensor, test_tgt_data_tensor, test_src_masks_tensor = df.prepare_data_for_transformer(test_data, test_masked_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy_with_tolerance(data, tg, bp, tolerance=10):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy of predictions in data against the target (tg),\n",
    "    only considering the positions marked as True in the blueprint (bp).\n",
    "    A prediction is considered correct if it is within 'tolerance' of the target.\n",
    "\n",
    "    Parameters:\n",
    "        data (list of lists): The predicted data with predictions injected at masked positions.\n",
    "        tg (list of lists): The target data to compare against, corresponding only to True mask positions.\n",
    "        bp (list of lists of bool): Mask indicating where predictions were injected.\n",
    "        tolerance (float): The tolerance level within which predictions are considered correct.\n",
    "\n",
    "    Returns:\n",
    "        float: The accuracy as a percentage of correct predictions.\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (seq, mask_seq, target_seq) in enumerate(zip(data, bp, tg)):\n",
    "        target_index = 0\n",
    "        for j, (mask, pred) in enumerate(zip(mask_seq, seq)):\n",
    "            if mask:\n",
    "                if target_index < len(target_seq):\n",
    "                    target = target_seq\n",
    "                    total += 1\n",
    "                    if abs(pred[0] - target[0]) <= tolerance and abs(pred[1] - target[1]) <= tolerance:\n",
    "                        correct += 1\n",
    "                    target_index += 1\n",
    "                else:\n",
    "                    print(\"Warning\")\n",
    "    if total == 0:\n",
    "        return 0  # Avoid division by zero\n",
    "    accuracy = (correct / total) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  1,  2,  2,  3,  3,  4,  4,  5,  5,  6,  6,  7,  7,  8,  8,  9,\n",
      "          9, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16, 17, 17, 18,\n",
      "         18, 19],\n",
      "        [ 1,  0,  2,  1,  3,  2,  4,  3,  5,  4,  6,  5,  7,  6,  8,  7,  9,  8,\n",
      "         10,  9, 11, 10, 12, 11, 13, 12, 14, 13, 15, 14, 16, 15, 17, 16, 18, 17,\n",
      "         19, 18]])\n"
     ]
    }
   ],
   "source": [
    "def create_simple_edge_index(num_points):\n",
    "    row = []\n",
    "    col = []\n",
    "    for i in range(num_points):\n",
    "        if i > 0:\n",
    "            row.append(i)\n",
    "            col.append(i - 1)\n",
    "        if i < num_points - 1:\n",
    "            row.append(i)\n",
    "            col.append(i + 1)\n",
    "    edge_index = torch.tensor([row, col], dtype=torch.long)\n",
    "    return edge_index\n",
    "\n",
    "# Example for 20 points\n",
    "edge_index = create_simple_edge_index(20)\n",
    "print(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-185.509165, -184.739612)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nd.unnormalize_point((0.13, 0.14), min_x, min_y, range_x, range_y)\n",
    "nd.unnormalize_point((0,0),  min_x, min_y, range_x, range_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "\n",
    "# src_data_tensor, tgt_data_tensor, src_masks_tensor = df.prepare_data_for_transformer(train_data, train_masked_point)\n",
    "\n",
    "# ## DEBUG\n",
    "\n",
    "\n",
    "# input_dim = 2\n",
    "# hidden_dim = 64                                                                                   \n",
    "# output_dim = 2\n",
    "# rate = 0.0001\n",
    "# val_loss_values = []\n",
    "# #model = md.SelfSupervisedModel(in_channels=3, out_channels=128, input_dim=128, model_dim=256, num_heads=8, num_layers=6, output_dim=3)\n",
    "# model = md.LSTMModel(2, 32, 2, 1)\n",
    "# loss_function = nn.MSELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=rate) ## w\n",
    "# scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6, verbose=True)\n",
    "\n",
    "\n",
    "# dataset = TensorDataset(src_data_tensor, tgt_data_tensor, src_masks_tensor)\n",
    "# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# val_dataset = TensorDataset(val_src_data_tensor, val_tgt_data_tensor, val_src_masks_tensor)\n",
    "# val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# ## TEMP\n",
    "# n_iters = 40\n",
    "# batch_size = 32\n",
    "\n",
    "\n",
    "# loss_values = []\n",
    "# accuracy_values = []\n",
    "\n",
    "# for epoch in range(n_iters):\n",
    "#     total_loss = 0\n",
    "#     model.train()\n",
    "#     for src, tgt, mask in dataloader:\n",
    "#         optimizer.zero_grad()\n",
    "#         output = model(src)\n",
    "#         masked_output = output  # Directly use the output for loss calculation\n",
    "#         loss = loss_function(masked_output, tgt)\n",
    "#         loss.backward()\n",
    "#         nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Apply gradient clipping\n",
    "#         optimizer.step()\n",
    "#         total_loss += loss.item()\n",
    "    \n",
    "#     avg_loss = total_loss / len(dataloader)\n",
    "#     loss_values.append(avg_loss)\n",
    "\n",
    "#     # Validation phase\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         val_total_loss = 0\n",
    "#         for src, tgt, mask in val_dataloader:\n",
    "#             output = model(src)\n",
    "#             masked_output = output\n",
    "#             val_loss = loss_function(masked_output, tgt)\n",
    "#             val_total_loss += val_loss.item()\n",
    "#         avg_val_loss = val_total_loss / len(val_dataloader)\n",
    "#         val_loss_values.append(avg_val_loss)\n",
    "#         print(f'Epoch {epoch+1}/{n_iters}, Validation Loss: {avg_val_loss}, Training Loss: {avg_loss}')\n",
    "\n",
    "#     # Step the learning rate scheduler\n",
    "#     scheduler.step(avg_val_loss)\n",
    "\n",
    "#     # Evaluation phase\n",
    "\n",
    "        \n",
    "# with torch.no_grad():\n",
    "#     predictions = model(test_src_data_tensor)\n",
    "#     data = test_src_data_tensor.tolist()\n",
    "#     bp = test_src_masks_tensor.tolist()\n",
    "#     tg = test_tgt_data_tensor.tolist()\n",
    "#     data1 = nd.unnormalize_data(data, min_x, min_y, range_x, range_y)\n",
    "#     tg = nd.unnormalize_points_list(tg, min_x, min_y, range_x, range_y)\n",
    "#     for i, (seq, mask_seq) in enumerate(zip(data, bp)):\n",
    "#         for j, mask in enumerate(mask_seq):\n",
    "#             if mask:\n",
    "#                 if data1[i][j] == nd.unnormalize_point((0, 0), min_x, min_y, range_x, range_y):\n",
    "#                     data1[i][j] = nd.unnormalize_point(list(predictions[i].tolist()), min_x, min_y, range_x, range_y)\n",
    "#                     data[i][j] = list(predictions[i].tolist())\n",
    "#     acc = calculate_accuracy_with_tolerance(data1, tg, bp, 5)\n",
    "#     accuracy_values.append(acc)\n",
    "#     print(f'Accuracy after Epoch {epoch+1}/{n_iters}: {acc:.2f}%')\n",
    "# # Plotting loss and accuracy\n",
    "# epochs = range(1, n_iters + 1)\n",
    "\n",
    "# plt.figure(figsize=(12, 5))\n",
    "\n",
    "# # Plot loss\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(epochs, loss_values, 'b', label='Loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training Loss')\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Training Loss: 0.0554, Validation Loss: 0.0449\n",
      "Epoch 2/20, Training Loss: 0.0456, Validation Loss: 0.0468\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/rr/Desktop/diff_transformers/project/main_run.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rr/Desktop/diff_transformers/project/main_run.ipynb#X20sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mfor\u001b[39;00m src, tgt, mask \u001b[39min\u001b[39;00m train_dataloader:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rr/Desktop/diff_transformers/project/main_run.ipynb#X20sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rr/Desktop/diff_transformers/project/main_run.ipynb#X20sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     output \u001b[39m=\u001b[39m model(src, edge_index)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rr/Desktop/diff_transformers/project/main_run.ipynb#X20sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_function(output, tgt)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rr/Desktop/diff_transformers/project/main_run.ipynb#X20sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/diff_transformers/project/model.py:115\u001b[0m, in \u001b[0;36mSelfSupervisedModel.forward\u001b[0;34m(self, x, edge_index, src_mask, tgt_mask)\u001b[0m\n\u001b[1;32m    112\u001b[0m gnn_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgnn(x, edge_index) \n\u001b[1;32m    113\u001b[0m gnn_output \u001b[39m=\u001b[39m gnn_output\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[0;32m--> 115\u001b[0m transformer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(gnn_output, src_mask)\n\u001b[1;32m    116\u001b[0m transformer_output \u001b[39m=\u001b[39m transformer_output\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m) \n\u001b[1;32m    118\u001b[0m \u001b[39mreturn\u001b[39;00m transformer_output[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/diff_transformers/project/model.py:97\u001b[0m, in \u001b[0;36mEquivariantTransformer.forward\u001b[0;34m(self, src, src_mask)\u001b[0m\n\u001b[1;32m     94\u001b[0m src \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding(src)\n\u001b[1;32m     95\u001b[0m src \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m) \n\u001b[0;32m---> 97\u001b[0m transformer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(src, src, src_mask, src_mask)\n\u001b[1;32m     99\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_out(transformer_output)\n\u001b[1;32m    100\u001b[0m \u001b[39mreturn\u001b[39;00m output\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/transformer.py:219\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask, src_is_causal, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mthe feature number of src and tgt must be equal to d_model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    217\u001b[0m memory \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(src, mask\u001b[39m=\u001b[39msrc_mask, src_key_padding_mask\u001b[39m=\u001b[39msrc_key_padding_mask,\n\u001b[1;32m    218\u001b[0m                       is_causal\u001b[39m=\u001b[39msrc_is_causal)\n\u001b[0;32m--> 219\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(tgt, memory, tgt_mask\u001b[39m=\u001b[39;49mtgt_mask, memory_mask\u001b[39m=\u001b[39;49mmemory_mask,\n\u001b[1;32m    220\u001b[0m                       tgt_key_padding_mask\u001b[39m=\u001b[39;49mtgt_key_padding_mask,\n\u001b[1;32m    221\u001b[0m                       memory_key_padding_mask\u001b[39m=\u001b[39;49mmemory_key_padding_mask,\n\u001b[1;32m    222\u001b[0m                       tgt_is_causal\u001b[39m=\u001b[39;49mtgt_is_causal, memory_is_causal\u001b[39m=\u001b[39;49mmemory_is_causal)\n\u001b[1;32m    223\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/transformer.py:494\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    491\u001b[0m tgt_is_causal \u001b[39m=\u001b[39m _detect_is_causal_mask(tgt_mask, tgt_is_causal, seq_len)\n\u001b[1;32m    493\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> 494\u001b[0m     output \u001b[39m=\u001b[39m mod(output, memory, tgt_mask\u001b[39m=\u001b[39;49mtgt_mask,\n\u001b[1;32m    495\u001b[0m                  memory_mask\u001b[39m=\u001b[39;49mmemory_mask,\n\u001b[1;32m    496\u001b[0m                  tgt_key_padding_mask\u001b[39m=\u001b[39;49mtgt_key_padding_mask,\n\u001b[1;32m    497\u001b[0m                  memory_key_padding_mask\u001b[39m=\u001b[39;49mmemory_key_padding_mask,\n\u001b[1;32m    498\u001b[0m                  tgt_is_causal\u001b[39m=\u001b[39;49mtgt_is_causal,\n\u001b[1;32m    499\u001b[0m                  memory_is_causal\u001b[39m=\u001b[39;49mmemory_is_causal)\n\u001b[1;32m    501\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    502\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(output)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/transformer.py:891\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    890\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal))\n\u001b[0;32m--> 891\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mha_block(x, memory, memory_mask, memory_key_padding_mask, memory_is_causal))\n\u001b[1;32m    892\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm3(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(x))\n\u001b[1;32m    894\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/transformer.py:909\u001b[0m, in \u001b[0;36mTransformerDecoderLayer._mha_block\u001b[0;34m(self, x, mem, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    907\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_mha_block\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor, mem: Tensor,\n\u001b[1;32m    908\u001b[0m                attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 909\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmultihead_attn(x, mem, mem,\n\u001b[1;32m    910\u001b[0m                             attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m    911\u001b[0m                             key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[1;32m    912\u001b[0m                             is_causal\u001b[39m=\u001b[39;49mis_causal,\n\u001b[1;32m    913\u001b[0m                             need_weights\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m    914\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout2(x)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/modules/activation.py:1266\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1252\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1253\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[1;32m   1254\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1263\u001b[0m         average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights,\n\u001b[1;32m   1264\u001b[0m         is_causal\u001b[39m=\u001b[39mis_causal)\n\u001b[1;32m   1265\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1266\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[1;32m   1267\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[1;32m   1268\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[1;32m   1269\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[1;32m   1270\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m   1271\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[1;32m   1272\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[1;32m   1273\u001b[0m         need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[1;32m   1274\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m   1275\u001b[0m         average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights,\n\u001b[1;32m   1276\u001b[0m         is_causal\u001b[39m=\u001b[39;49mis_causal)\n\u001b[1;32m   1277\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[1;32m   1278\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/torch/nn/functional.py:5504\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5501\u001b[0m k \u001b[39m=\u001b[39m k\u001b[39m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[1;32m   5502\u001b[0m v \u001b[39m=\u001b[39m v\u001b[39m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[0;32m-> 5504\u001b[0m attn_output \u001b[39m=\u001b[39m scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n\u001b[1;32m   5505\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mpermute(\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(bsz \u001b[39m*\u001b[39m tgt_len, embed_dim)\n\u001b[1;32m   5507\u001b[0m attn_output \u001b[39m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "\n",
    "src_data_tensor, tgt_data_tensor, src_masks_tensor = df.prepare_data_for_transformer(train_data, train_masked_point)\n",
    "in_channels = 2  # Number of features in GNN input (x, y)\n",
    "hidden_channels = 64  # Hidden layer dimension in GNN\n",
    "out_channels = 128  # Output dimension from GNN\n",
    "model_dim = 256  # Dimension for transformer model\n",
    "num_heads = 8  # Number of attention heads in transformer\n",
    "num_layers = 6  # Number of layers in transformer\n",
    "output_dim = 2  # Output dimension (x, y)\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = md.SelfSupervisedModel(in_channels, hidden_channels, out_channels, model_dim, num_heads, num_layers, output_dim)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-6, verbose=True)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(src_data_tensor, tgt_data_tensor, src_masks_tensor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(val_src_data_tensor, val_tgt_data_tensor, val_src_masks_tensor)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Create edge_index for 20 points (fully connected)\n",
    "edge_index = create_simple_edge_index(20)\n",
    "\n",
    "# Training loop\n",
    "n_iters = 20\n",
    "loss_values = []\n",
    "val_loss_values = []\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for src, tgt, mask in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, edge_index)\n",
    "        loss = loss_function(output, tgt)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    loss_values.append(avg_loss)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt, mask in val_dataloader:\n",
    "            output = model(src, edge_index)\n",
    "            val_loss = loss_function(output, tgt)\n",
    "            val_total_loss += val_loss.item()\n",
    "    \n",
    "    avg_val_loss = val_total_loss / len(val_dataloader)\n",
    "    val_loss_values.append(avg_val_loss)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{n_iters}, Training Loss: {avg_loss:.4f}, Validation Loss: {avg_val_loss:.4f}')\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "# Evaluation phase\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(test_src_data_tensor, edge_index)\n",
    "    print(\"Predictions Shape:\", predictions.shape)\n",
    "\n",
    "    data = test_src_data_tensor.tolist()\n",
    "    print(\"Test Data Shape:\", test_src_data_tensor.shape)\n",
    "    bp = test_src_masks_tensor.tolist()\n",
    "    tg = test_tgt_data_tensor.tolist()\n",
    "\n",
    "    data = nd.unnormalize_data(data, min_x, min_y, range_x, range_y)\n",
    "    tg = nd.unnormalize_points_list(tg, min_x, min_y, range_x, range_y)\n",
    "    \n",
    "    for i, (seq, mask_seq) in enumerate(zip(data, bp)):\n",
    "        for j, mask in enumerate(mask_seq):\n",
    "            if mask:\n",
    "                if data[i][j] == nd.unnormalize_point((0, 0), min_x, min_y, range_x, range_y):\n",
    "                    data[i][j] = nd.unnormalize_point(predictions[i].tolist(), min_x, min_y, range_x, range_y)\n",
    "\n",
    "    acc = calculate_accuracy_with_tolerance(data, tg, bp, 40)\n",
    "    print(f'Accuracy after Epoch {n_iters}: {acc:.2f}%')\n",
    "\n",
    "# Plotting loss\n",
    "epochs = range(1, n_iters + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot training loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, loss_values, 'b', label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot validation loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, val_loss_values, 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_trajectory(model, trajectory):\n",
    "    \"\"\"\n",
    "    Predicts the output for a single trajectory using the trained model.\n",
    "    \n",
    "    Parameters:\n",
    "        model (torch.nn.Module): The trained model.\n",
    "        trajectory (any): The input trajectory data formatted as required by the model.\n",
    "        device (str): The device to use ('cpu' or 'cuda').\n",
    "    \n",
    "    Returns:\n",
    "        Any: The prediction made by the model.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(src_data_tensor)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data\", src_data_tensor)\n",
    "print(\"Prediction:\", prediction)\n",
    "print(\"red\", src_masks_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = src_data_tensor.tolist()\n",
    "bp = src_masks_tensor.tolist()\n",
    "tg = tgt_data_tensor.tolist()\n",
    "for i, (seq, mask_seq) in enumerate(zip(data, bp)):\n",
    "    for j, mask in enumerate(mask_seq):\n",
    "        if mask:\n",
    "            if data[i][j] == [0.0, 0.0]:\n",
    "                data[i][j] = list(prediction[i].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = nd.unnormalize_points_list(data[300], min_x, min_y, range_x, range_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [point[0] for point in line]\n",
    "y = [point[1] for point in line]\n",
    "print(x, y)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y, label='Data Line', marker='o')\n",
    "ax.set_xlabel('X Coordinates')\n",
    "ax.set_ylabel('Y Coordinates')\n",
    "ax.set_title('Plot of Data Points')\n",
    "ax.legend()\n",
    "ax.set_xlim([0, 1050])\n",
    "ax.set_ylim([0, 1050])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = dm.create_synthetic(1, 1000, 1000, 0, 0, 20)\n",
    "train, min_x, min_y, range_x, range_y = nd.normalize_data(trajectories, min_x, min_y, range_x, range_y)\n",
    "train_data, train_masked_point = df.mask_point_at_index(train, 6)\n",
    "src_data_tensor, tgt_data_tensor, src_masks_tensor = df.prepare_data_for_transformer(test_data, test_masked_point)\n",
    "prediction = predict_single_trajectory(model, src_data_tensor)\n",
    "print(predictions.shape)\n",
    "data = src_data_tensor.tolist()\n",
    "bp = src_masks_tensor.tolist()\n",
    "tg = tgt_data_tensor.tolist()\n",
    "data1 = nd.unnormalize_data(data, min_x, min_y, range_x, range_y)\n",
    "tg = nd.unnormalize_points_list(tg, min_x, min_y, range_x, range_y)\n",
    "for i, (seq, mask_seq) in enumerate(zip(data, bp)):\n",
    "    for j, mask in enumerate(mask_seq):\n",
    "        if mask:\n",
    "            if data1[i][j] == nd.unnormalize_point((0,0),  min_x, min_y, range_x, range_y):\n",
    "                data1[i][j] = nd.unnormalize_point(list(prediction[i].tolist()),min_x, min_y, range_x, range_y)\n",
    "                data[i][j] = list(prediction[i].tolist())\n",
    "acc = calculate_accuracy_with_tolerance(data1, tg, bp, 20)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
